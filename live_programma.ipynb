{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57164fdb-622c-4f22-a7f1-693d20748189",
   "metadata": {},
   "source": [
    "# Notebook: Live application \n",
    "\n",
    "This notebook contains the version of the live program of the master thesis of Theo Vandeportaele. It saves all the necesarry graphs and data of the players of both teams and works on data of the StatsPerform FTP server. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a119037-eac3-4c9d-b5ff-a49976d649a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import floodlight.io.statsperform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import io\n",
    "\n",
    "from floodlight.core.xy import XY\n",
    "from floodlight.models.kinematics import DistanceModel\n",
    "from floodlight.models.kinematics import VelocityModel\n",
    "from datetime import datetime\n",
    "from ftplib import FTP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1effd523-4ca7-4ef3-a51f-a33915346b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make FTP connection\n",
    "ftp_host = 'soccer-ftp.stats.com'\n",
    "ftp_username = ''\n",
    "ftp_password = ''\n",
    "\n",
    "ftp = FTP(ftp_host)\n",
    "ftp.login(ftp_username, ftp_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2d746-15fc-4be1-8074-93790aa3aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose the right folder with the data \n",
    "ftp_id = 20240421\n",
    "ftp_comp = 'belgium'\n",
    "ftp_home = 'unionsaintgilloise'\n",
    "ftp_away = 'clubbrugge'\n",
    "\n",
    "# Path to the folder where the new files are added\n",
    "path = f\"/XYZ/{ftp_id}_{ftp_comp}_{ftp_home}_vs_{ftp_away}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba854b-ae45-4e22-b09d-99b228ca8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Home' team or 'Away' team \n",
    "if ftp_home == 'clubbrugge': \n",
    "    team = 'Home'\n",
    "else:\n",
    "    team = 'Away'\n",
    "    \n",
    "# Shirt numbers of all players of Club Brugge, numbers of players not playing will be skipped\n",
    "shirt_numbers = ['22', '29', '4', '6', '14', '44', '55', '58', '64', '10', '15', '20', '27', '39', '62', '77', '7', '8', '9', '11', '32', '68', '99', '17', '26', '70', '28', '66', '76']\n",
    "last_values = {number: (0, 0) for number in shirt_numbers}\n",
    "\n",
    "# Create empty numpy array for the frames \n",
    "current_frames = np.empty((0, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330d60b-f59e-4c0b-b87b-f9282754c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the average distance dictionary from the json file - Get average line\n",
    "file_path_dist = 'average_distance.json'\n",
    "\n",
    "with open(file_path_dist, 'r') as file_dist:\n",
    "    avg_dist_dict = json.load(file_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ae745-aa10-45fb-bd60-c038fc4d27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the average velocity dictionary from the json file - Get average line\n",
    "file_path_vel = 'average_velocity_frames.json'\n",
    "\n",
    "with open(file_path_vel, 'r') as file_vel:\n",
    "    vel_dict = json.load(file_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5a938-515f-42d7-8780-dafeac4d596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the average velocity dictionary from the json file - Get average to calculate the frames \n",
    "file_path_vel = 'average_velocity.json'\n",
    "\n",
    "with open(file_path_vel, 'r') as file_vel:\n",
    "    avg_vel_dict = json.load(file_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de0ab5-d55f-47c1-be94-2e29db3339c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize last_modification_time globally\n",
    "last_modification_time = None  \n",
    "\n",
    "# Function that checks if there are new files in the folder\n",
    "def new_file_in_folder(path):\n",
    "    global last_modification_time  \n",
    "\n",
    "    ftp.cwd(path)\n",
    "    \n",
    "    files = ftp.nlst()\n",
    "\n",
    "    if not files:\n",
    "        print(\"No files found in the folder.\")\n",
    "        return False\n",
    "\n",
    "    # Find the newest file\n",
    "    newest_file = max(files, key=lambda f: ftp.sendcmd('MDTM ' + f)[4:])\n",
    "    \n",
    "    # Get the modification time of the newest file\n",
    "    new_modification_time = ftp.sendcmd('MDTM ' + newest_file)[4:]\n",
    "\n",
    "    # Check if the modification time of the newest file is newer than the last checked file \n",
    "    if new_modification_time != last_modification_time:\n",
    "        print(\"A new file has been found:\", newest_file)\n",
    "        last_modification_time = new_modification_time\n",
    "        \n",
    "        # Read data if the file is newer \n",
    "        read_data(ftp, newest_file)   \n",
    "        return True\n",
    "    else:\n",
    "        print(\"No new files found in the folder.\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2219cb0a-71ed-4ddf-a714-5c8cfa020d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Cartesian distance between two points\n",
    "def cartesian_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((float(x2) - float(x1))**2 + (float(y2) - float(y1))**2)\n",
    "\n",
    "# Dictionaries to store ID and latest positions\n",
    "id_dict = {}\n",
    "latest_dict = {}\n",
    "\n",
    "# Global variable for some test value\n",
    "test_getal = 0\n",
    "\n",
    "# Function that reads the data and parses it to the format needed for floodlight\n",
    "def read_data(file):\n",
    "    global current_frames\n",
    "    global id_dict\n",
    "    global last_values\n",
    "    global latest_dict\n",
    "    global test_getal\n",
    "\n",
    "    # Set the filename for the tracking data\n",
    "    filename_tracking_data = file\n",
    "\n",
    "    # Read the data in the file\n",
    "    with open(filename_tracking_data, 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    # List to store parsed coordinates\n",
    "    xy = []\n",
    "\n",
    "    # Iterate over each line in the data file\n",
    "    for line in data:\n",
    "        line_counter = 0\n",
    "        parsed_arrays = []\n",
    "\n",
    "        # Strip the line to remove unneeded parts and split it\n",
    "        parts = line.strip().split(':')[1]\n",
    "        player_parts = parts.strip().split(';')\n",
    "\n",
    "        # Counter to check if all necessary numbers are present\n",
    "        shirt_number_counter = 0\n",
    "        \n",
    "        # Dictionary to store the latest positions of players in the current line\n",
    "        latest_dict_new = latest_dict\n",
    "\n",
    "        # Iterate over each player in the current line\n",
    "        for player in player_parts:\n",
    "            if player:\n",
    "                # Split player info into chunks:\n",
    "                # 0: Home or away team (or keeper - not relevant)\n",
    "                # 1: ID (not useful as it changes constantly)\n",
    "                # 2: Kit number (sometimes -1 if not defined yet)\n",
    "                # 3 & 4: x-coord and y-coord data\n",
    "                player_chunck = player.strip().split(',')\n",
    "\n",
    "                # If the player doesn't have a jersey number, the line is not useful\n",
    "                shirt_number = player_chunck[2]\n",
    "                \n",
    "                if shirt_number == '-1':\n",
    "                    cart = 100000\n",
    "                    # Find the closest player in the latest_dict\n",
    "                    for i in latest_dict:\n",
    "                        cart_dist = cartesian_distance(player_chunck[3], player_chunck[4], latest_dict[i][0], latest_dict[i][1])\n",
    "                        if cart_dist < cart:\n",
    "                            cart = cart_dist\n",
    "                            if cart_dist != 100000:\n",
    "                                shirt_number = i\n",
    "                else:\n",
    "                    # Increment counter if player is from home or away team\n",
    "                    if player_chunck[0] == '0' or player_chunck[0] == '3':\n",
    "                        shirt_number_counter += 1\n",
    "\n",
    "                # Increment line counter for home or away team players\n",
    "                if player_chunck[0] == '0' or player_chunck[0] == '3':\n",
    "                    line_counter += 1\n",
    "\n",
    "                # Update dictionaries for valid players\n",
    "                if shirt_number != '-1' and (player_chunck[0] == '0' or player_chunck[0] == '3'):\n",
    "                    id_dict[player_chunck[1]] = shirt_number\n",
    "                    latest_dict_new[shirt_number] = (player_chunck[3], player_chunck[4])\n",
    "                    last_values[shirt_number] = (player_chunck[3], player_chunck[4])\n",
    "\n",
    "        # Update the latest_dict with new positions\n",
    "        latest_dict = latest_dict_new\n",
    "        \n",
    "        # Append the coordinates in last_values to a numpy array\n",
    "        for number in shirt_numbers:\n",
    "            parsed_arrays.append(last_values[number][0])\n",
    "            parsed_arrays.append(last_values[number][1])\n",
    "\n",
    "        # If the number of shirt_numbers is within the expected range, add to array\n",
    "        if shirt_number_counter >= 6 and shirt_number_counter <= 13:\n",
    "            np_parsed = np.array(parsed_arrays)\n",
    "            xy.append(np_parsed)\n",
    "\n",
    "    # Check if the array has enough data\n",
    "    if len(xy) >= 1000:\n",
    "        if len(xy) == 1500:\n",
    "            test_getal += 1\n",
    "        # Add the current array of the current file to the global array with the data\n",
    "        add_frames(np.asarray(xy, dtype=\"object\"))\n",
    "    else:\n",
    "        print(f\"File too short: {len(xy)}\")\n",
    "    print(f'Size: {current_frames.shape}')\n",
    "\n",
    "    # Make graph if the file isn't empty\n",
    "    if current_frames.shape[0] > 1:\n",
    "        make_graphs(current_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b662315-d4ee-4298-8290-5cf67fe6f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add frames of new file to global frames array \n",
    "def add_frames(xy):\n",
    "    global current_frames\n",
    "    \n",
    "    if len(xy.shape) == 2:\n",
    "        current_frames = np.concatenate((current_frames, xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73279d50-9c53-4675-90a5-3d3349578bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to smooth data using previous values within a kernel size\n",
    "def smooth_previous_only(data, kernel_size=20):\n",
    "    smoothed_data = []\n",
    "    for i in range(len(data)):\n",
    "        if i < kernel_size:\n",
    "            window = data[:i+1]\n",
    "        else:\n",
    "            window = data[i-kernel_size+1:i+1]\n",
    "        smoothed_value = int(np.mean(window))  \n",
    "        smoothed_data.append(smoothed_value)\n",
    "    return np.array(smoothed_data)\n",
    "\n",
    "# Function to create and save graphs based on the processed data\n",
    "def make_graphs(xy):\n",
    "    global times_loop\n",
    "\n",
    "    folder_path = 'now_live'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    times_loop += 1\n",
    "    \n",
    "    # Create numpy array of the data\n",
    "    array_data = np.array(xy)\n",
    "\n",
    "    # Convert each array to float type\n",
    "    float_arrays = [arr.astype(float) for arr in array_data]\n",
    "\n",
    "    xy_values_array = np.asarray(float_arrays, dtype=object)\n",
    "\n",
    "    # Create an XY object for floodlight\n",
    "    xy_values = XY(xy=xy_values_array, framerate=25, direction=None)    \n",
    "\n",
    "    # Create distance and velocity models\n",
    "    dm = DistanceModel()\n",
    "    dm.fit(xy_values)\n",
    "    cumulative_distance_covered = dm.cumulative_distance_covered()\n",
    "\n",
    "    vm = VelocityModel()\n",
    "    vm.fit(xy_values)\n",
    "    vm.velocity()\n",
    "\n",
    "    # Prevent graphs from being displayed\n",
    "    plt.ioff()\n",
    "\n",
    "    # Close all the plots that were open before this step\n",
    "    plt.close('all')\n",
    "\n",
    "    # Counter to decide where the players should be on the plot \n",
    "    counter = 0\n",
    "    \n",
    "    for i in shirt_numbers: \n",
    "        try: \n",
    "            # Calculate which data belongs to the specific player \n",
    "            mapped_index = shirt_numbers.index(i)\n",
    "            cumulative_distance_data = cumulative_distance_covered.property[:, mapped_index]\n",
    "    \n",
    "            # Create buckets that contain the total cumulative data per minute instead of the cumulative data per 0.04 seconds\n",
    "            data_points_per_minute = 25 * 60\n",
    "            downsampled_data = cumulative_distance_data[::data_points_per_minute]\n",
    "            cumulative_distance_per_minute = np.gradient(downsampled_data)\n",
    "    \n",
    "            # Remove 0 values, which indicate player substitutions\n",
    "            cumulative_distance_per_minute = cumulative_distance_per_minute[cumulative_distance_per_minute != 0]\n",
    "    \n",
    "            # Use the custom smoothing function\n",
    "            smoothed_array = smooth_previous_only(cumulative_distance_per_minute)\n",
    "    \n",
    "            # Calculate the average value of the smoothed array\n",
    "            average_distance = avg_dist_dict[str(i)]    \n",
    "\n",
    "            # Add the distance data of the players to the subplot \n",
    "            fig_dist, axs_dist = plt.subplots(figsize=(10, 8))\n",
    "            axs_dist.set_title(f'Slope of Cumulative Distance of Player {i}', fontsize=16)\n",
    "            axs_dist.set_xlabel('Time (minutes)', fontsize=16)\n",
    "            axs_dist.set_ylabel('Slope per Minute', fontsize=16)\n",
    "            axs_dist.grid(True)\n",
    "            axs_dist.plot(smoothed_array, label=f'Player {i}')\n",
    "            axs_dist.axhline(y=average_distance, color='green', linestyle='--', label='Average')\n",
    "\n",
    "            # Save the distance subplot\n",
    "            player_folder_path = os.path.join(folder_path, f'player_{i}')\n",
    "            os.makedirs(player_folder_path, exist_ok=True)\n",
    "            fig_dist_path = os.path.join(player_folder_path, f'{i}_distance_{times_loop}.png')\n",
    "            fig_dist.savefig(fig_dist_path)\n",
    "            plt.close(fig_dist)\n",
    "\n",
    "            # Get velocity model data for the specific player \n",
    "            total_velocity = vm.velocity()[:, mapped_index]\n",
    "\n",
    "            # Calculate the velocity threshold \n",
    "            avg = avg_vel_dict[i]\n",
    "            velocity = avg * 2\n",
    "\n",
    "            # Check how many frames are above the velocity threshold \n",
    "            above_threshold_mask = total_velocity > velocity\n",
    "            elements_above_threshold = np.sum(above_threshold_mask)\n",
    "    \n",
    "            # Create buckets per minute and remove the 0 values\n",
    "            minutes = 1\n",
    "            frame_size = 25 * minutes * 60\n",
    "            num_frames = len(above_threshold_mask) // frame_size\n",
    "            counts_array = np.zeros(num_frames, dtype=int)\n",
    "            above_threshold_mask_reshaped = above_threshold_mask[:num_frames * frame_size].reshape(num_frames, frame_size)\n",
    "            counts_array = np.sum(above_threshold_mask_reshaped, axis=1)\n",
    "            counts_array = np.trim_zeros(counts_array, 'b')\n",
    "\n",
    "            # Use the custom smoothing function\n",
    "            smoothed_count_array = smooth_previous_only(counts_array)\n",
    "\n",
    "            # Get value for average velocity line \n",
    "            average_vel = vel_dict[str(i)]\n",
    "            \n",
    "            # Add the velocity data of the players to the subplot \n",
    "            fig_vel, axs_vel = plt.subplots(figsize=(10, 8))\n",
    "            axs_vel.set_title(f'Amount of frames above certain velocity by player {i}', fontsize=16)\n",
    "            axs_vel.set_xlabel('Time (minutes)', fontsize=16)\n",
    "            axs_vel.set_ylabel('Number of frames above 2 times average velocity', fontsize=16)\n",
    "            axs_vel.grid(True)\n",
    "            axs_vel.plot(smoothed_count_array, label=f'Player {i}', color='red')\n",
    "            axs_vel.axhline(y=average_vel, color='green', linestyle='--', label='Average')\n",
    "\n",
    "            # Save the velocity subplot\n",
    "            fig_vel_path = os.path.join(player_folder_path, f'{i}_velocity_{times_loop}.png')\n",
    "            fig_vel.savefig(fig_vel_path)\n",
    "            plt.close(fig_vel)\n",
    "\n",
    "            # Update counter \n",
    "            counter += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred by player {i}: {e}\")\n",
    "\n",
    "    # Close any remaining plots\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ea6f8-9216-4f03-8a38-0091a129fdcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# While loop that constantly runs, checks for new files and executes the necesarry functions \n",
    "while(True): \n",
    "    new_file_in_folder(path)\n",
    "    time.sleep(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8752b8-cb79-46a4-8029-ba947aa135b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33824612-40ea-432f-80fa-97dbba34ed87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21ec521-543d-4ab3-96c6-6fa02bd869b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
