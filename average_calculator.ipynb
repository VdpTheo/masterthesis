{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e278dd4-7ea0-47d8-aaea-9dbd0b109608",
   "metadata": {},
   "source": [
    "# Average calculator:\n",
    "This notebook is part of the offline and online program of the master thesis of Theo Vandeportaele. It calculates the average values that can be used to represent the average lines on the distance and velocity graphs. These values are calculated based on the previous games during a season. The notebook consists of two main parts:\n",
    "- Average Distance Calculator\n",
    "- Average Velocity Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a462a60f-aab6-4afa-9557-9359d38585b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import floodlight.io.statsperform\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import re\n",
    "\n",
    "from tqdm import tqdm\n",
    "from floodlight.core.xy import XY\n",
    "from floodlight.models.kinematics import DistanceModel\n",
    "from floodlight.models.kinematics import VelocityModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea19437c-1476-45d9-ad9c-2b5ff1343b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba1480f-41c8-4026-8859-b7a4e90af358",
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_sort(value):\n",
    "    numbers = re.compile(r'(\\d+)')\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9d0a2e-cfe9-4e11-b298-e92b2a90b48f",
   "metadata": {},
   "source": [
    "## Average Distance Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d2c732-dd55-4f17-a40e-75f118cd17b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe04dcc6-4b66-4900-b421-fd7b5c6bffef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Itterate over all folders in the path folder\n",
    "# Each folder represents the data of a different game played this season\n",
    "\n",
    "for file in tqdm(sorted(os.listdir(path), key=numerical_sort)):\n",
    "    # Create tracking file full path\n",
    "    filename = os.fsdecode(file)\n",
    "    filename_tracking_data = path + filename\n",
    "    print(filename_tracking_data)\n",
    "        \n",
    "    # Get teamsheets of tracking file\n",
    "    teamsheets = floodlight.io.statsperform.read_teamsheets_from_position_data_txt(filename_tracking_data)\n",
    "\n",
    "    # Find out if Club Brugge is the home or away team     \n",
    "    truncated_filename = filename.split(\"-\", 1)[-1]\n",
    "    print(truncated_filename)\n",
    "    if truncated_filename.startswith(\"Club Brugge\"):\n",
    "        team = 'Home'\n",
    "    else: \n",
    "        team = 'Away'\n",
    "    print(team)\n",
    "\n",
    "    # Get tracking data\n",
    "    data = floodlight.io.statsperform.read_position_data_txt(filename_tracking_data)\n",
    "\n",
    "    #\n",
    "    #\n",
    "    # CALCULATION OF AVERAGE DISTANCE\n",
    "    #\n",
    "    #\n",
    "    \n",
    "    # Create distance model and get cumulative distance of first half\n",
    "    xy_values = data[0][1][team]\n",
    "\n",
    "    dm = DistanceModel()\n",
    "    dm.fit(xy_values)\n",
    "    cumulative_distance_covered = dm.cumulative_distance_covered()\n",
    "\n",
    "    # Create distance model and get cumulative distance of second half\n",
    "    xy_values_second = data[0][2][team]\n",
    "\n",
    "    dm_2 = DistanceModel()\n",
    "    dm_2.fit(xy_values_second)\n",
    "    cumulative_distance_covered_2 = dm_2.cumulative_distance_covered()\n",
    "\n",
    "    # Create id_mapping table to map the tracking file ID to the shirt number of the player\n",
    "    id_mapping = data[1][team]    \n",
    "\n",
    "    # Itterate over all the players that player in that specific game\n",
    "    for player_id in teamsheets[team]['jID']:\n",
    "\n",
    "        # Use the id_mapping table to get the shirt number of the current player\n",
    "        mapped_index = id_mapping[id_mapping['jID'] == player_id]['xID'].values.tolist()[0]-1\n",
    "\n",
    "        # Get the cumulative distance data of only that specific player\n",
    "        cumulative_distance_data = cumulative_distance_covered.property[:, mapped_index]\n",
    "        cumulative_distance_data_2 = cumulative_distance_covered_2.property[:, mapped_index]\n",
    "\n",
    "        # Add the last element of the cumulative model of the first half to all the values of the second half\n",
    "        # Otherwise the values of the second half start again from 0\n",
    "        last_element_data_1 = cumulative_distance_data[-1]\n",
    "        result_array = cumulative_distance_data_2 + last_element_data_1\n",
    "\n",
    "        # Concatenate the cumulative data from the first and the second half\n",
    "        total_cum_data = np.concatenate((cumulative_distance_data, result_array), axis=0)\n",
    "\n",
    "        # Create buckets that contain the total cumulative data per minute instead of the cumulative data per 0.04 seconds (original is per 0.04 seconds) \n",
    "        data_points_per_minute = 25 * 60\n",
    "        downsampled_data = total_cum_data[::data_points_per_minute]\n",
    "        cumulative_distance_per_minute = np.gradient(downsampled_data)\n",
    "\n",
    "        # If cumulative data per minute = 0; than delete it. This only happens after a player is substituted out or before a player is substituted in\n",
    "        cumulative_distance_per_minute = cumulative_distance_per_minute[cumulative_distance_per_minute != 0]\n",
    "\n",
    "        # Use a kernel to smoothen the graph. \n",
    "        kernel_size = 20\n",
    "        kernel = np.ones(kernel_size) / kernel_size\n",
    "        padded_counts_array = np.pad(cumulative_distance_per_minute, (kernel_size // 2, kernel_size // 2), mode='symmetric')\n",
    "        smoothed_array = np.convolve(padded_counts_array, kernel, mode='valid')\n",
    "\n",
    "        # Calculate the average value of the smoothed array\n",
    "        average_value = np.mean(smoothed_array)\n",
    "        \n",
    "        # Save this average value in a dictionary. If the player_id isn't yet present, just save it.\n",
    "        # If the player_id is already present, save the average of that value and the average_value. This makes sure that recent games have a bigger\n",
    "        # influence on the average_value than the first couple of games of the season. \n",
    "        if smoothed_array.size >= 45:\n",
    "            if player_id in dist_dict: \n",
    "                dist_dict[player_id] = (dist_dict[player_id] + average_value) / 2\n",
    "            else:\n",
    "                dist_dict[player_id] = average_value    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636772e4-be20-431e-9ef1-ca9f85f66dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the average values in the dictionary to a json file \n",
    "file_path = \"average_distance_05.json\"\n",
    "\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(dist_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895db9b9-76be-4caa-a22c-cfcb6947ad38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93bd2a23-a808-4734-86ac-bb4e5b3536c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c113d5bd-3803-4a49-95fb-1418286ecda9",
   "metadata": {},
   "source": [
    "## Average Velocity Calculator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422988c8-86b8-4936-8e86-6a35708128fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_dict = {}\n",
    "vel_avg_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341577a-c2fb-400e-b4a4-413984fdc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in tqdm(sorted(os.listdir(path), key=numerical_sort)):\n",
    "    # Create tracking file full path\n",
    "    filename = os.fsdecode(file)\n",
    "    filename_tracking_data = path + filename\n",
    "    print(filename_tracking_data)\n",
    "        \n",
    "    # Get teamsheets of tracking file\n",
    "    teamsheets = floodlight.io.statsperform.read_teamsheets_from_position_data_txt(filename_tracking_data)\n",
    "    # print(teamsheets)\n",
    "\n",
    "    # Find out if Club Brugge is the home or away team    \n",
    "    truncated_filename = filename.split(\"-\", 1)[-1]\n",
    "    print(truncated_filename)\n",
    "    if truncated_filename.startswith(\"Club Brugge\"):\n",
    "        team = 'Home'\n",
    "    else: \n",
    "        team = 'Away'\n",
    "    print(team)\n",
    "\n",
    "    # Get tracking data\n",
    "    data = floodlight.io.statsperform.read_position_data_txt(filename_tracking_data)\n",
    "\n",
    "    #\n",
    "    #\n",
    "    # CALCULATION OF AVERAGE VELOCITY\n",
    "    #\n",
    "    #\n",
    "\n",
    "    # Create velocity model and get velocity of first half\n",
    "    xy_values = data[0][1][team]\n",
    "\n",
    "    vm = VelocityModel()\n",
    "    vm.fit(xy_values)\n",
    "    vm.velocity()\n",
    "\n",
    "    # Create velocity model and get velocity of second half\n",
    "    xy_values_second = data[0][2][team]\n",
    "\n",
    "    vm_2 = VelocityModel()\n",
    "    vm_2.fit(xy_values_second)\n",
    "    vm_2.velocity()\n",
    "\n",
    "    # Create id_mapping table to map the tracking file ID to the shirt number of the player\n",
    "    id_mapping = data[1][team]    \n",
    "    \n",
    "    for player_id in teamsheets[team]['jID']:\n",
    "        \n",
    "        # Use the id_mapping table to get the shirt number of the current player\n",
    "        mapped_index = id_mapping[id_mapping['jID'] == player_id]['xID'].values.tolist()[0]-1\n",
    "\n",
    "        # Get the velocity of the specific player\n",
    "        velocity_1 = vm.velocity()[:,mapped_index]\n",
    "        velocity_2 = vm_2.velocity()[:,mapped_index]\n",
    "\n",
    "        # Concatenate velocity of first and second half \n",
    "        total_velocity = np.concatenate((velocity_1, velocity_2), axis=0)\n",
    "\n",
    "        # Calculate the average velocity of the player and multiply by 2\n",
    "        avg = np.nanmean(total_velocity)\n",
    "        \n",
    "        velocity = avg*2\n",
    "        if player_id in vel_avg_dict: \n",
    "            vel_avg_dict[player_id] = (vel_avg_dict[player_id] + avg) / 2\n",
    "        else:\n",
    "            vel_avg_dict[player_id] = avg    \n",
    "\n",
    "\n",
    "        # Like explained during my presentation. I'm going to calculate the amount of frames above a certain value (2*avg_velocity) per minute. \n",
    "        # Create a mask to see when the value is above the velocity value and count the amount of times it's higher. \n",
    "        above_threshold_mask = total_velocity > velocity\n",
    "        elements_above_threshold = np.sum(above_threshold_mask)\n",
    "\n",
    "        # Make buckets per minute and remove the 0 values, since values are only 0 if \n",
    "        minutes = 1\n",
    "        frame_size = 25*minutes*60\n",
    "        num_frames = len(above_threshold_mask) // frame_size\n",
    "        counts_array = np.zeros(num_frames, dtype=int)\n",
    "        above_threshold_mask_reshaped = above_threshold_mask[:num_frames * frame_size].reshape(num_frames, frame_size)\n",
    "        counts_array = np.sum(above_threshold_mask_reshaped, axis=1)\n",
    "        counts_array = np.trim_zeros(counts_array, 'b')\n",
    "\n",
    "        # Calculate the average value and add it to the dictionary. If the player_id isn't yet present, just save it.\n",
    "        # If the player_id is already present, save the average of that value and the average_value. This makes sure that recent games have a bigger\n",
    "        # influence on the average_value than the first couple of games of the season. \n",
    "        average_value = np.mean(counts_array)\n",
    "        if average_value >= 100:\n",
    "            if player_id in vel_dict: \n",
    "                vel_dict[player_id] = (vel_dict[player_id] + average_value) / 2\n",
    "            else:\n",
    "                vel_dict[player_id] = average_value    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51b5b4c-fb0f-4c5f-8a2c-346637278816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a json file. \n",
    "file_path = \"average_velocity_frames_05.json\"\n",
    "\n",
    "# Write the dictionary to the JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(vel_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56173f7-1f28-4cff-a308-5af00e9b3336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the dictionary to a json file. \n",
    "file_path = \"average_velocity_05.json\"\n",
    "\n",
    "# Write the dictionary to the JSON file\n",
    "with open(file_path, 'w') as json_file:\n",
    "    json.dump(vel_avg_dict, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72136a87-5fb1-444e-8c14-00336b9fb59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679e5ac6-7e0b-48b3-89f5-b01051f8a73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vel_avg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33390fd4-b64c-4cab-b11a-bd73942d3854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5dfe57b-9812-45f4-a7ee-5e48de13fe79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
