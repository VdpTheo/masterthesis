{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57164fdb-622c-4f22-a7f1-693d20748189",
   "metadata": {},
   "source": [
    "# Notebook: Live application - simulation\n",
    "\n",
    "This notebook contains the first version of the live program of my master thesis. It doesn't really work on live games, but works with a simulation of the FTP server (where the files are normally stored during the live game). So while simulating the FTP server, it saves all the necesarry graphs and data of the players. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a119037-eac3-4c9d-b5ff-a49976d649a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import floodlight.io.statsperform\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import keyboard\n",
    "import math\n",
    "\n",
    "from floodlight.core.xy import XY\n",
    "from floodlight.models.kinematics import DistanceModel\n",
    "from floodlight.models.kinematics import VelocityModel\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c7346c-3d55-4ba7-80a6-0d224021e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map shirt numbers to players\n",
    "shirt_number_mapping_rev = {\n",
    "    '22': 'Mignolet',\n",
    "    '29': 'Jacker',\n",
    "    '4': 'Ordóñez',\n",
    "    '6': 'Odoi',\n",
    "    '14': 'Meijer',\n",
    "    '44': 'Mechele',\n",
    "    '55': 'De Cuyper',\n",
    "    '58': 'Spileers',\n",
    "    '64': 'Sabbe',\n",
    "    '10': 'Vetlesen',\n",
    "    '15': 'Onyedika',\n",
    "    '20': 'Vanaken',\n",
    "    '27': 'Nielsen',\n",
    "    '39': 'Balanta',\n",
    "    '62': 'Homma',\n",
    "    '77': 'Zinckernagel',\n",
    "    '7': 'Skov Olsen',\n",
    "    '8': 'Skóras',\n",
    "    '9': 'Jutgla',\n",
    "    '11': 'Barbera',\n",
    "    '32': 'Nusa',\n",
    "    '68': 'Talbi',\n",
    "    '99': 'Thiago', \n",
    "    '17': 'Buchanan', \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ba854b-ae45-4e22-b09d-99b228ca8d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder where the new files are added\n",
    "path = ''\n",
    "\n",
    "# Jersey numbers of all players\n",
    "shirt_numbers = ['22', '29', '4', '6', '14', '44', '55', '58', '64', '10', '15', '20', '27', '39', '62', '77', '7', '8', '9', '11', '32', '68', '99', '17', '26', '70', '28', '66', '76']\n",
    "last_values = {number: (0, 0) for number in shirt_numbers}\n",
    "\n",
    "# Create empty numpy array for the frames \n",
    "# current_frames = np.empty((0, 58))\n",
    "current_frames = np.empty((0, 22))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a330d60b-f59e-4c0b-b87b-f9282754c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the average distance dictionary from the json file - Get average line\n",
    "file_path_dist = ''\n",
    "\n",
    "with open(file_path_dist, 'r') as file_dist:\n",
    "    avg_dist_dict = json.load(file_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6ae745-aa10-45fb-bd60-c038fc4d27d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the average velocity dictionary from the json file - Get average line\n",
    "file_path_vel = ''\n",
    "\n",
    "with open(file_path_vel, 'r') as file_vel:\n",
    "    vel_dict = json.load(file_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5a938-515f-42d7-8780-dafeac4d596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the average velocity dictionary from the json file - Get average to calculate the frames \n",
    "file_path_vel = ''\n",
    "\n",
    "with open(file_path_vel, 'r') as file_vel:\n",
    "    avg_vel_dict = json.load(file_vel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5de0ab5-d55f-47c1-be94-2e29db3339c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to keep track of processed files\n",
    "processed_files = []\n",
    "\n",
    "def new_file_in_folder(path):\n",
    "    global processed_files  # Access the global processed_files list\n",
    "\n",
    "    # Get a list of files in the specified folder\n",
    "    files = os.listdir(path)\n",
    "    \n",
    "    # Check if there are any files in the folder\n",
    "    if not files:\n",
    "        print(\"No files found in the folder.\")\n",
    "        return False\n",
    "    \n",
    "    # Iterate over the list of files to check for new files\n",
    "    for file_name in files:\n",
    "        file_path = os.path.join(path, file_name)  # Get the full path of the file\n",
    "        if file_name not in processed_files:  # Check if the file has not been processed yet\n",
    "            print(\"A new file has been found:\", file_name)\n",
    "            processed_files.append(file_name)  # Add the new file to the processed list\n",
    "            read_data(file_path)  # Read data from the new file (assume read_data is defined elsewhere)\n",
    "            break  # Stop checking after the first new file is found\n",
    "    \n",
    "    print(\"No new files found in the folder.\")\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4d24c1-8eb3-4d20-a31f-c0614019dea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the Cartesian distance between two points\n",
    "def cartesian_distance(x1, y1, x2, y2):\n",
    "    return math.sqrt((float(x2) - float(x1))**2 + (float(y2) - float(y1))**2)\n",
    "\n",
    "# Dictionaries to store ID and latest positions\n",
    "id_dict = {}\n",
    "latest_dict = {}\n",
    "\n",
    "# Global variable for some test value\n",
    "test_getal = 0\n",
    "\n",
    "# Function that reads the data and parses it to the format needed for floodlight\n",
    "def read_data(file):\n",
    "    global current_frames\n",
    "    global id_dict\n",
    "    global last_values\n",
    "    global latest_dict\n",
    "    global test_getal\n",
    "\n",
    "    # Set the filename for the tracking data\n",
    "    filename_tracking_data = file\n",
    "\n",
    "    # Read the data in the file\n",
    "    with open(filename_tracking_data, 'r') as file:\n",
    "        data = file.readlines()\n",
    "\n",
    "    # List to store parsed coordinates\n",
    "    xy = []\n",
    "\n",
    "    # Iterate over each line in the data file\n",
    "    for line in data:\n",
    "        line_counter = 0\n",
    "        parsed_arrays = []\n",
    "\n",
    "        # Strip the line to remove unneeded parts and split it\n",
    "        parts = line.strip().split(':')[1]\n",
    "        player_parts = parts.strip().split(';')\n",
    "\n",
    "        # Counter to check if all necessary numbers are present\n",
    "        shirt_number_counter = 0\n",
    "        \n",
    "        # Dictionary to store the latest positions of players in the current line\n",
    "        latest_dict_new = latest_dict\n",
    "\n",
    "        # Iterate over each player in the current line\n",
    "        for player in player_parts:\n",
    "            if player:\n",
    "                # Split player info into chunks:\n",
    "                # 0: Home or away team (or keeper - not relevant)\n",
    "                # 1: ID (not useful as it changes constantly)\n",
    "                # 2: Kit number (sometimes -1 if not defined yet)\n",
    "                # 3 & 4: x-coord and y-coord data\n",
    "                player_chunck = player.strip().split(',')\n",
    "\n",
    "                # If the player doesn't have a jersey number, the line is not useful\n",
    "                shirt_number = player_chunck[2]\n",
    "                \n",
    "                if shirt_number == '-1':\n",
    "                    cart = 100000\n",
    "                    # Find the closest player in the latest_dict\n",
    "                    for i in latest_dict:\n",
    "                        cart_dist = cartesian_distance(player_chunck[3], player_chunck[4], latest_dict[i][0], latest_dict[i][1])\n",
    "                        if cart_dist < cart:\n",
    "                            cart = cart_dist\n",
    "                            if cart_dist != 100000:\n",
    "                                shirt_number = i\n",
    "                else:\n",
    "                    # Increment counter if player is from home or away team\n",
    "                    if player_chunck[0] == '0' or player_chunck[0] == '3':\n",
    "                        shirt_number_counter += 1\n",
    "\n",
    "                # Increment line counter for home or away team players\n",
    "                if player_chunck[0] == '0' or player_chunck[0] == '3':\n",
    "                    line_counter += 1\n",
    "\n",
    "                # Update dictionaries for valid players\n",
    "                if shirt_number != '-1' and (player_chunck[0] == '0' or player_chunck[0] == '3'):\n",
    "                    id_dict[player_chunck[1]] = shirt_number\n",
    "                    latest_dict_new[shirt_number] = (player_chunck[3], player_chunck[4])\n",
    "                    last_values[shirt_number] = (player_chunck[3], player_chunck[4])\n",
    "\n",
    "        # Update the latest_dict with new positions\n",
    "        latest_dict = latest_dict_new\n",
    "        \n",
    "        # Append the coordinates in last_values to a numpy array\n",
    "        for number in shirt_numbers:\n",
    "            parsed_arrays.append(last_values[number][0])\n",
    "            parsed_arrays.append(last_values[number][1])\n",
    "\n",
    "        # If the number of shirt_numbers is within the expected range, add to array\n",
    "        if shirt_number_counter >= 6 and shirt_number_counter <= 13:\n",
    "            np_parsed = np.array(parsed_arrays)\n",
    "            xy.append(np_parsed)\n",
    "\n",
    "    # Check if the array has enough data\n",
    "    if len(xy) >= 1000:\n",
    "        if len(xy) == 1500:\n",
    "            test_getal += 1\n",
    "        # Add the current array of the current file to the global array with the data\n",
    "        add_frames(np.asarray(xy, dtype=\"object\"))\n",
    "    else:\n",
    "        print(f\"File too short: {len(xy)}\")\n",
    "    print(f'Size: {current_frames.shape}')\n",
    "\n",
    "    # Make graph if the file isn't empty\n",
    "    if current_frames.shape[0] > 1:\n",
    "        make_graphs(current_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b662315-d4ee-4298-8290-5cf67fe6f00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add frames of new file to global frames array \n",
    "def add_frames(xy):\n",
    "    global current_frames\n",
    "\n",
    "    print(xy.shape)\n",
    "    print(current_frames.shape)\n",
    "    \n",
    "    if len(xy.shape) == 2:\n",
    "        current_frames = np.concatenate((current_frames, xy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c94af3-ee17-4ce1-bd2f-4bb8937fc325",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to smooth data using previous values within a kernel size\n",
    "def smooth_previous_only(data, kernel_size=20):\n",
    "    smoothed_data = []\n",
    "    for i in range(len(data)):\n",
    "        if i < kernel_size:\n",
    "            window = data[:i+1]\n",
    "        else:\n",
    "            window = data[i-kernel_size+1:i+1]\n",
    "        smoothed_value = int(np.mean(window))  \n",
    "        smoothed_data.append(smoothed_value)\n",
    "    return np.array(smoothed_data)\n",
    "\n",
    "# Function to create and save graphs based on the processed data\n",
    "def make_graphs(xy):\n",
    "    global times_loop        \n",
    "\n",
    "    folder_path = 'now_live'\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "    \n",
    "    times_loop = times_loop + 1\n",
    "    \n",
    "    # Create numpy array of the data\n",
    "    array_data = np.array(xy)\n",
    "\n",
    "    # Convert each array to float type\n",
    "    float_arrays = [arr.astype(float) for arr in array_data]\n",
    "\n",
    "    xy_values_array = np.asarray(float_arrays, dtype=object)\n",
    "\n",
    "    # Create an XY object for floodlight\n",
    "    xy_values = XY(xy=xy_values_array, framerate=25, direction=None)    \n",
    "\n",
    "    # Create distance and velocity models\n",
    "    dm = DistanceModel()\n",
    "    dm.fit(xy_values)\n",
    "    cumulative_distance_covered = dm.cumulative_distance_covered()\n",
    "\n",
    "    vm = VelocityModel()\n",
    "    vm.fit(xy_values)\n",
    "    vm.velocity()\n",
    "\n",
    "    # Prevent graphs from being displayed\n",
    "    plt.ioff()\n",
    "\n",
    "    # Close all the plots that were open before this step\n",
    "    plt.close('all')\n",
    "\n",
    "    counter = 0\n",
    "\n",
    "    all_players_data = {}\n",
    "    \n",
    "    for i in shirt_numbers: \n",
    "        try: \n",
    "            if i == '44': \n",
    "                # Calculate which data belongs to the specific player \n",
    "                mapped_index = shirt_numbers.index(i)\n",
    "                cumulative_distance_data = cumulative_distance_covered.property[:, mapped_index]\n",
    "        \n",
    "                # Create buckets that contain the total cumulative data per minute instead of per 0.04 seconds\n",
    "                data_points_per_minute = 25 * 60\n",
    "                downsampled_data = cumulative_distance_data[::data_points_per_minute]\n",
    "                cumulative_distance_per_minute = np.gradient(downsampled_data)\n",
    "        \n",
    "                # Remove 0 values, which indicate player substitutions\n",
    "                cumulative_distance_per_minute = cumulative_distance_per_minute[cumulative_distance_per_minute != 0]\n",
    "        \n",
    "                # Use the custom smoothing function\n",
    "                smoothed_array = smooth_previous_only(cumulative_distance_per_minute)\n",
    "        \n",
    "                # Calculate the average value of the smoothed array\n",
    "                average_distance = 141\n",
    "                \n",
    "                # Add the distance data of the players to the subplot \n",
    "                fig_dist, axs_dist = plt.subplots(figsize=(10, 8))\n",
    "                axs_dist.set_title(f'Slope of cumulative coefficient of player {i} (Online)', fontsize=20)\n",
    "                axs_dist.set_xlabel('Time (minutes)', fontsize=20)\n",
    "                axs_dist.set_ylabel('Slope per minute', fontsize=20)\n",
    "                axs_dist.grid(True)\n",
    "                axs_dist.plot(smoothed_array)\n",
    "                axs_dist.axhline(y=average_distance, color='green', linestyle='--', label='Average')\n",
    "    \n",
    "                # Save the distance subplot\n",
    "                player_folder_path = os.path.join(folder_path, f'{shirt_number_mapping_rev[i]}')\n",
    "                os.makedirs(player_folder_path, exist_ok=True)\n",
    "                fig_dist_path = os.path.join(player_folder_path, f'{i}_distance_{times_loop}.png')\n",
    "                fig_dist.savefig(fig_dist_path)\n",
    "                plt.close(fig_dist)\n",
    "    \n",
    "                # Get velocity model data for the specific player \n",
    "                total_velocity = vm.velocity()[:, mapped_index]\n",
    "    \n",
    "                # Calculate the velocity threshold \n",
    "                avg = avg_vel_dict[i]\n",
    "                velocity = avg * 2\n",
    "    \n",
    "                # Check how many frames are above the velocity threshold \n",
    "                above_threshold_mask = total_velocity > velocity\n",
    "                elements_above_threshold = np.sum(above_threshold_mask)\n",
    "        \n",
    "                # Create buckets per minute and remove the 0 values\n",
    "                minutes = 1\n",
    "                frame_size = 25 * minutes * 60\n",
    "                num_frames = len(above_threshold_mask) // frame_size\n",
    "                counts_array = np.zeros(num_frames, dtype=int)\n",
    "                above_threshold_mask_reshaped = above_threshold_mask[:num_frames * frame_size].reshape(num_frames, frame_size)\n",
    "                counts_array = np.sum(above_threshold_mask_reshaped, axis=1)\n",
    "                counts_array = np.trim_zeros(counts_array, 'b')\n",
    "    \n",
    "                # Get value for average velocity line \n",
    "                average_vel = 190\n",
    "        \n",
    "                # Use the custom smoothing function\n",
    "                smoothed_count_array = smooth_previous_only(counts_array)\n",
    "    \n",
    "                # Add the velocity data of the players to the subplot \n",
    "                fig_vel, axs_vel = plt.subplots(figsize=(10, 8))\n",
    "                axs_vel.set_title(f'Number of frames 2 times above average velocity for player {i}', fontsize=20)\n",
    "                axs_vel.set_xlabel('Time (minutes)', fontsize=20)\n",
    "                axs_vel.set_ylabel('Number of frames per minute', fontsize=20)\n",
    "                axs_vel.grid(True)\n",
    "                axs_vel.plot(smoothed_count_array, color='red')\n",
    "                axs_vel.axhline(y=average_vel, color='green', linestyle='--', label='Average')\n",
    "    \n",
    "                # Save the velocity subplot\n",
    "                fig_vel_path = os.path.join(player_folder_path, f'{i}_velocity_{times_loop}.png')\n",
    "                fig_vel.savefig(fig_vel_path)\n",
    "                plt.close(fig_vel)\n",
    "    \n",
    "                # Store player data in a dictionary\n",
    "                player_data = {\n",
    "                    \"smoothed_array\": smoothed_array.tolist(),\n",
    "                    \"average_distance\": average_distance,\n",
    "                    \"smoothed_count_array\": smoothed_count_array.tolist(),\n",
    "                    \"average_vel\": average_vel\n",
    "                }\n",
    "                \n",
    "                all_players_data[i] = player_data\n",
    "    \n",
    "                # Update counter \n",
    "                counter += 1\n",
    "        \n",
    "        except Exception as e:\n",
    "            if \"can't extend empty axis 0 using modes other than 'constant' or 'empty'\" in str(e):\n",
    "                pass\n",
    "            else:\n",
    "                print(f\"An error occurred for player {i}: {e}\")\n",
    "        \n",
    "    # Write all player data to a JSON file\n",
    "    json_folder_path = os.path.join(folder_path, f\"physical_data\")\n",
    "    os.makedirs(json_folder_path, exist_ok=True)\n",
    "    json_file_name = f'physical_data_{times_loop}.json'\n",
    "    json_file_path = os.path.join(json_folder_path, json_file_name)\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(all_players_data, json_file)\n",
    "\n",
    "    plt.close('all')  # Close any remaining plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3ea6f8-9216-4f03-8a38-0091a129fdcc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "times_loop = 0\n",
    "\n",
    "# While loop that constantly runs, checks for new files and executes the necesarry functions \n",
    "while(True): \n",
    "    new_file_in_folder(path)\n",
    "    \n",
    "    time.sleep(30)\n",
    "    \n",
    "    if keyboard.is_pressed('esc'):\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
